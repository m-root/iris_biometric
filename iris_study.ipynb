{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "Preprocess the image to isolate the iris from the rest of the image. This involves several steps, including:\n",
    "\n",
    "Localization: Identify the iris within the image.\n",
    "Normalization: Adjust the image to a common scale and orientation.\n",
    "Enhancement: Improve the image quality, often by increasing contrast or reducing noise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-05T10:33:13.414793Z",
     "start_time": "2023-08-05T10:33:12.325819Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pywt\n",
    "import numpy as np\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from shapely.geometry import Point, Polygon\n",
    "from skimage import filters\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "# Iris Localization\n",
    "def iris_localization(image):\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # apply Gaussian blur\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # apply Canny edge detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # apply Hough Circle Transform\n",
    "    circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "\n",
    "    # find the circle with the largest radius (assuming this is the iris)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        # sort the circles by radius in descending order\n",
    "        circles = sorted(circles, key=lambda x: -x[2])\n",
    "        x, y, r = circles[0]\n",
    "        iris_region = image[y-r:y+r, x-r:x+r]\n",
    "    else:\n",
    "        iris_region = None\n",
    "\n",
    "    return iris_region\n",
    "\n",
    "def iris_normalization(iris_region, pupil_center, iris_radius, eyelid_contour=None):\n",
    "    # ensure iris_region is grayscale\n",
    "    if len(iris_region.shape) == 3:\n",
    "        iris_region = cv2.cvtColor(iris_region, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # define the dimensions of the normalized iris image\n",
    "    rows, cols = (32, 256)\n",
    "    normalized_iris = np.zeros((rows, cols))\n",
    "\n",
    "    # create an interpolation function for the iris region\n",
    "    iris_region_interpolate = RectBivariateSpline(np.arange(iris_region.shape[0]), np.arange(iris_region.shape[1]), iris_region)\n",
    "\n",
    "    # create a polygon for the eyelid contour if one is provided\n",
    "    if eyelid_contour is not None:\n",
    "        eyelid_polygon = Polygon(eyelid_contour)\n",
    "\n",
    "    # compute the angle and radius for each point in the normalized iris image\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            theta = 2*np.pi*j/cols\n",
    "            r = i/rows\n",
    "            x = pupil_center[0] + r*iris_radius*np.cos(theta)\n",
    "            y = pupil_center[1] + r*iris_radius*np.sin(theta)\n",
    "\n",
    "            # check if the point is within the eyelid contour, if one is provided\n",
    "            if eyelid_contour is not None and eyelid_polygon.contains(Point(x, y)):\n",
    "                # if the point is within the eyelid contour, assign a default value\n",
    "                normalized_iris[i, j] = 0  # or any other default value\n",
    "            else:\n",
    "                # check if the point falls inside the iris region\n",
    "                if 0 <= x < iris_region.shape[1] and 0 <= y < iris_region.shape[0]:\n",
    "                    normalized_iris[i, j] = iris_region_interpolate(y, x)[0, 0]  # extract the scalar value\n",
    "                else:\n",
    "                    # if the point falls outside the iris region, assign a default value\n",
    "                    normalized_iris[i, j] = 0  # or any other default value\n",
    "\n",
    "    return normalized_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extraction\n",
    "Extract features from the image. These features represent the unique aspects of the individual's iris. Various methods can be used for feature extraction, including wavelet transforms, Gabor filters, and others."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def gabor_feature_extraction(normalized_iris):\n",
    "    # define the orientations and frequencies for the Gabor filters\n",
    "    orientations = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    frequencies = [0.2, 0.4, 0.6, 0.8]\n",
    "    gabor_features = []\n",
    "\n",
    "    for orientation in orientations:\n",
    "        for frequency in frequencies:\n",
    "            gabor_response_real, gabor_response_imag = filters.gabor(normalized_iris, frequency=frequency, theta=orientation)\n",
    "            gabor_features.extend(gabor_response_real.flatten())\n",
    "            gabor_features.extend(gabor_response_imag.flatten())\n",
    "\n",
    "    return np.array(gabor_features)\n",
    "\n",
    "\n",
    "def wavelet_feature_extraction(normalized_iris):\n",
    "    # perform a wavelet transform on the normalized iris\n",
    "    coeffs = pywt.wavedec2(normalized_iris, 'haar')\n",
    "\n",
    "    # flatten the wavelet coefficients to create a feature vector\n",
    "    wavelet_features = np.hstack([coeff.ravel() for coeff in coeffs[0]] +\n",
    "                             [value.ravel() for coeff in coeffs[1:] for value in coeff])\n",
    "\n",
    "    return wavelet_features\n",
    "\n",
    "def feature_extraction(normalized_iris):\n",
    "    # apply Gabor filters for feature extraction\n",
    "    gabor_features = gabor_feature_extraction(normalized_iris)\n",
    "\n",
    "    # apply wavelet transform for feature extraction\n",
    "    wavelet_features = wavelet_feature_extraction(normalized_iris)\n",
    "\n",
    "    # concatenate the Gabor and wavelet features to create a combined feature vector\n",
    "    features = np.concatenate([gabor_features, wavelet_features])\n",
    "\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T10:33:37.484674Z",
     "start_time": "2023-08-05T10:33:37.479677Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Post-processing\n",
    "\n",
    "Use the result of the matching process to make a decision. This might involve accepting or rejecting the individual's claimed identity, or it could involve further steps such as updating the database or notifying security personnel.\n",
    "\n",
    "Matching: The extracted features are then compared to the features in a database of known individuals. If the features match closely enough, the individual is identified.\n",
    "\n",
    "Post-processing: Finally, the result of the matching process is used to make a decision. This might involve accepting or rejecting the individual's claimed identity, or it could involve further steps such as updating the database or notifying security personnel."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03978455  0.0362278   0.02970633 ... -2.71562533 -1.51401062\n",
      " -3.2516927 ]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image = cv2.imread(\"iris_image/2/left/bryanl1.bmp\")\n",
    "iris_region = iris_localization(image)\n",
    "\n",
    "if iris_region is not None:\n",
    "    # placeholder values for pupil_center, iris_radius, and eyelid_contour\n",
    "    pupil_center = (iris_region.shape[1]//2, iris_region.shape[0]//2)\n",
    "    iris_radius = min(pupil_center)\n",
    "    eyelid_contour = None  # no eyelid contour is provided\n",
    "\n",
    "    normalized_iris = iris_normalization(iris_region, pupil_center, iris_radius, eyelid_contour)\n",
    "    features = feature_extraction(normalized_iris)\n",
    "    print(features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T10:33:41.093105Z",
     "start_time": "2023-08-05T10:33:41.008324Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array hash: 39FD3D3302FBC44D985451E849B65DC4F9EB58AB1242125C86AF4235008ECB6B\n"
     ]
    }
   ],
   "source": [
    "# Convert the array to a byte string\n",
    "array_string = features.tobytes()\n",
    "\n",
    "# Create a SHA-256 hash of the byte string\n",
    "array_hash = hashlib.sha256(array_string).hexdigest()\n",
    "\n",
    "print(\"Array hash:\", array_hash.upper())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T12:15:48.454868Z",
     "start_time": "2023-08-05T12:15:48.439817Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
